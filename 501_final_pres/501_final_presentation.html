<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title>Time Series Clustering: A Review</title>
<meta name="author" content="(Philipp Beer)"/>
<meta name="description" content="Literature review in time series clustering"/>
<meta name="keywords" content="unic, 501dl, stassopoulou"/>
<style type="text/css">
.underline { text-decoration: underline; }
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js/dist/reveal.css"/>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/reveal.js/dist/theme/blood.css" id="theme"/>


<!-- If the query includes 'print-pdf', include the PDF print sheet -->
<script>
    if( window.location.search.match( /print-pdf/gi ) ) {
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = 'https://cdn.jsdelivr.net/npm/reveal.js/css/print/pdf.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
    }
</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
<div class="reveal">
<div class="slides">
<style>
.reveal table {
    font-size: 0.6em;
}

.reveal p {
    font-size: 0.8em;
}
</style>

<style>
#left {
  left:-8.33%;
  text-align: left;
  float: left;
  width:50%;
  z-index:-10;
}

#right {
  left:31.25%;
  top: 75px;
  float: right;
  text-align: right;
  z-index:-10;
  width:50%;
}
</style>




<section>
<section id="slide-org4a25fc6">
<h2 id="org4a25fc6">Time Series Clustering: A Review</h2>

<div id="org53880e3" class="figure">
<p><img src="https://philippbeer.github.io/unic/501_final_pres/img/unic_logo.png" alt="unic_logo.png" width="200px" />
</p>
</div>

<p>
Philipp Beer<br />
Gradudate Program Data Science, UNIC<br />
Prof. Athena Stassopoulou
</p>
</section>
</section>
<section>
<section id="slide-org0991306">
<h3 id="org0991306">Why you should listen to this talk</h3>
<p>
If you want to <b>utilize time series</b> to create <b>forecasts</b>,<br />
<b>learn about their properties</b> or<br />
<b>want to learn what is missing the research of time series clustering</b><br />
(IMHO) you should listen to this talk.
</p>
</section>
</section>
<section>
<section id="slide-org221e427">
<h3 id="org221e427">Introduction</h3>
<ul>
<li>no bothering with names or particular studies - read the review</li>
<li>time series analysis is pervasive to many areas</li>

</ul>

</section>
<section id="slide-org7fbabe5">
<h4 id="org7fbabe5">Applications</h4>
<p>
forecasting,<br />
reporting,<br />
analytics
</p>
</section>
<section id="slide-orge8224b7">
<h4 id="orge8224b7">Fields</h4>
<p>
natural sciences,<br />
engineering,<br />
finance,<br />
medicine,<br />
robotics
</p>
</section>
<section id="slide-orgb187ff2">
<h4 id="orgb187ff2">Challenges in time series analysis</h4>
<ul>
<li data-fragment-index="1" class="fragment fade-in-then-out">utilization of time series is hard</li>
<li data-fragment-index="2" class="fragment fade-in-then-out">countless properties to consider</li>
<li data-fragment-index="3" class="fragment fade-in-then-out">oftentimes only limited set of historical data available</li>

</ul>
</section>
<section id="slide-orgac4c793">
<h4 id="orgac4c793">Focus of this review</h4>
<ol>
<li class="fragment fade-in-then-semi-out">Definition  of terms clustering, time series and similarity measures</li>
<li class="fragment fade-in-then-semi-out">Properties to cluster by</li>
<li class="fragment fade-in-then-semi-out">Distance metrics categories</li>
<li class="fragment fade-in-then-semi-out">Clustering algorithms categories</li>
<li class="fragment fade-in-then-semi-out">Assessment</li>
<li class="fragment fade-in-then-semi-out">Limitations</li>
<li class="fragment fade-in-then-semi-out">Conclusion</li>

</ol>

</section>
</section>
<section>
<section id="slide-org154f4b4">
<h3 id="org154f4b4">Definitions</h3>
<div class="outline-text-3" id="text-org154f4b4">
</div>
</section>
<section id="slide-orga2bc044">
<h4 id="orga2bc044">Clustering</h4>
<div id="left">

<div id="org2113804" class="figure">
<p><img src="https://philippbeer.github.io/unic/501_final_pres/img/xray_vision.jpg" alt="xray_vision.jpg" class="fragment grow" />
</p>
<p><span class="figure-number">Figure 2: </span>1979 - The Health Education Council DC Comics</p>
</div>
</div>
<div id="right">
<ul>
<li class="fragment fade-in-then-semi-out"><b>unsupervised</b> learning technique</li>
<li class="fragment fade-in-then-semi-out">reveal patterns useful for exploitations</li>
<li class="fragment fade-in-then-semi-out">segmentation, grouping, distinction of elements into groups</li>

</ul>
</div>
</section>
<section id="slide-org2a6759b">
<h4 id="org2a6759b">Time series</h4>
<p class="fragment fade-in-then-semi-out">
<b>sequence composed by a series of continuous, real-valued elements</b>
</p>

<ul>
<li class="fragment fade-in-then-out">share the same challenges as high dimensional data</li>
<li class="fragment fade-in-then-out">"curse of dimensionality"</li>
<li class="fragment fade-in-then-out">quickly requires high computational power to process</li>

</ul>

</section>
<section id="slide-org7a1074c">
<h4 id="org7a1074c">Similarity measure in time series</h4>
<ul>
<li class="fragment fade-in">measure of how similar series are</li>
<li class="fragment fade-in">usually computed pair-wise</li>

</ul>

</section>
<section id="slide-orgd997592">
<h4 id="orgd997592">Utility of Time series clustering</h4>
<p class="fragment fade-in-then-semi-out">
anomalies, novelties, discord
</p>

<ul>
<li class="fragment appear">discover dynamic changes</li>
<li class="fragment appear">discover patterns</li>
<li class="fragment appear">increase accuracy in predictions</li>

</ul>

</section>
</section>
<section>
<section id="slide-orgc668007">
<h3 id="orgc668007">Clustering time series by</h3>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Shape-based</th>
<th scope="col" class="org-left">Feature-based</th>
<th scope="col" class="org-left">Model-based</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left"><img src="https://philippbeer.github.io/unic/501_final_pres/img/shape_based_clustering.png" alt="shape_based_clustering.png" /></td>
<td class="org-left"><img src="https://philippbeer.github.io/unic/501_final_pres/img/feature_based_clustering.png" alt="feature_based_clustering.png" /></td>
<td class="org-left">transform raw ts to model paramenters</td>
</tr>
</tbody>
</table>

</section>
</section>
<section>
<section id="slide-orgb83c47e">
<h3 id="orgb83c47e">Distance metrics</h3>
<ul>
<li>cornerstone of the clustering algorithm</li>
<li>categories: <b>stable</b> and <b>approximate</b></li>

</ul>
</section>
<section id="slide-orgdf75410">
<h4 id="orgdf75410">Stable distance metrics</h4>
<p>
Euclidean distance
  \[ d(p,q) = \sqrt{(p_1 - q_1)^2 + \cdots + (p_n - q_n)^2} \]
</p>
<ul>
<li>raw time series requires same length</li>
<li>no large outliers</li>
<li>limited noise</li>

</ul>
<aside class="notes">
<ul>
<li>Euclidean distance (ED) is very sensitive to unique features (outliers, noise)</li>
<li>ED requires same length time series</li>

</ul>

</aside>
</section>
<section id="slide-org8f5dff2">
<h4 id="org8f5dff2">approximate metrics</h4>

<div id="org261aafd" class="figure">
<p><img src="https://philippbeer.github.io/unic/501_final_pres/img/dtw_metric.png" alt="dtw_metric.png" width="500px" />
</p>
</div>
<ul>
<li>can handle different length time series</li>
<li>Dynamic Time Warping (DTW)</li>

</ul>
<aside class="notes">
<ul>
<li>other metrics address part of these issues (e.g. DTW)</li>
<li>other methods introduce other issues (DTW - warping around local extremes)</li>
<li>complex methods often require parameters that can heavily impact performance (e.g. warping window)</li>
<li>more eloquent methods introduce high computational costs</li>

</ul>

</aside>

</section>
<section id="slide-org5c568e5">
<h4 id="org5c568e5">Current state of research</h4>
<ul>
<li><b>missing framework</b> how to choose these metrics</li>
<li>aim: identify new metrics or improve upon existing</li>

</ul>

</section>
</section>
<section>
<section id="slide-orgbe7455f">
<h3 id="orgbe7455f">Clustering Algorithms I</h3>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Partional</th>
<th scope="col" class="org-left">Hierarchical</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left"><img src="https://philippbeer.github.io/unic/501_final_pres/img/partional.png" alt="partional.png" /></td>
<td class="org-left"><img src="https://philippbeer.github.io/unic/501_final_pres/img/dendogram.png" alt="dendogram.png" /></td>
</tr>
</tbody>
</table>
<aside class="notes">
<ul>
<li>grouping unlabeled data in groups</li>
<li>input parameter: <b>k</b></li>
<li>distinguished into crisp and fuzzy</li>

</ul>

</aside>

</section>
</section>
<section>
<section id="slide-org96a226d">
<h3 id="org96a226d">Clustering Algorithms II</h3>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Density-Based</th>
<th scope="col" class="org-left">Grid-based</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left"><img src="https://philippbeer.github.io/unic/501_final_pres/img/dbscan.png" alt="dbscan.png" /></td>
<td class="org-left"><img src="https://philippbeer.github.io/unic/501_final_pres/img/grid_based.png" alt="grid_based.png" /></td>
</tr>
</tbody>
</table>



</section>
</section>
<section>
<section id="slide-org22d234e">
<h3 id="org22d234e">Partional</h3>
<div class="outline-text-3" id="text-org22d234e">
</div>
</section>
<section id="slide-org670299b">
<h4 id="org670299b">Advantages</h4>
<ul>
<li>easy to understand and implement</li>
<li>utilizable with different distance metrics</li>

</ul>

</section>
<section id="slide-org85aa8f7">
<h4 id="org85aa8f7">Challenges</h4>
<ul>
<li>limited to globular shapes</li>
<li>easily impacted by noise and outliers</li>

</ul>
</section>
</section>
<section>
<section id="slide-org094e46b">
<h3 id="org094e46b">Hierarchical</h3>
<aside class="notes">
<ul>
<li>bottom-up and top-down approaches</li>
<li>distance measure: single-, average-, complete-link</li>

</ul>

</aside>
</section>
<section id="slide-org25ecb01">
<h4 id="org25ecb01">Advantages</h4>
<ul>
<li>visual analysis</li>
<li>no predetermination of k required</li>

</ul>

</section>
<section id="slide-org9f7223f">
<h4 id="org9f7223f">Challenges</h4>
<ul>
<li>no adjustments after decision about an element made</li>
<li>computational complexity: \[ \mathcal{O}(N^2) \]</li>

</ul>
</section>
</section>
<section>
<section id="slide-org7647b7f">
<h3 id="org7647b7f">Density-based methods</h3>
<aside class="notes">
<ul>
<li>DBSCAN - two parameters (neighbourhood and minimum for points)</li>

</ul>

</aside>
</section>
<section id="slide-org324cb19">
<h4 id="org324cb19">Advantages</h4>
<ul>
<li>can <b>handle non-globular shapes</b> well</li>
<li><b>quick</b> execution speed</li>
<li>is capable of <b>identifying noise and outliers</b></li>
<li>those properties make it applicable to a wide variety of data sets</li>

</ul>

</section>
<section id="slide-orga65937c">
<h4 id="orga65937c">Challenges</h4>
<ul>
<li>correct setup of parameters requires higher understanding of the data</li>
<li><b>varying cluster densities</b> create a challenge</li>
<li>not often applied in time series due to this complexity</li>

</ul>
</section>
</section>
<section>
<section id="slide-orgb2a3821">
<h3 id="orgb2a3821">Grid-based methods</h3>
<aside class="notes">
<ul>
<li>quantizing the feature space into hyper-rectangles (cells)</li>
<li>for each range of those intervals the respective metrics are computed</li>

</ul>

</aside>
</section>
<section id="slide-org4b1634b">
<h4 id="org4b1634b">Advantages</h4>
<ul>
<li>single pass computation \[ \mathcal{O}(N) \]</li>
<li>very fast query impacted only by number of grids (k): \[ \mathcal{O}(k) \]</li>

</ul>

</section>
<section id="slide-org5dbbb78">
<h4 id="org5dbbb78">Challenges</h4>
<ul>
<li><b>NO</b> relationship between the grids</li>
<li>interval range is a manual parameter</li>
<li><b>Research Question</b>: Can these ranges be inferred from the data?</li>

</ul>
</section>
</section>
<section>
<section id="slide-org7b5ebad">
<h3 id="org7b5ebad">Assessment metrics</h3>
<div class="outline-text-3" id="text-org7b5ebad">
</div>
</section>
<section id="slide-org521af4a">
<h4 id="org521af4a">General points</h4>
<ul>
<li>trickiest part of the process</li>
<li>metrics are separated into <b>external</b> and <b>internal</b> metrics</li>

</ul>
</section>
<section id="slide-org87e8571">
<h4 id="org87e8571">External indexes</h4>
<ul>
<li>validation of clusters that exist outside of algorithm (often ground truth)</li>
<li>degree of matching between two partitions</li>
<li>Cluster Purity, Rand Index, F-measure, Entropy, Jaccard index</li>

</ul>
</section>
<section id="slide-org73fca2a">
<h4 id="org73fca2a">Internal indexes</h4>
<ul>
<li>evaluation of a goodness of clustered structure</li>
<li>core idea: elements of same cluster close together / elements of other clusters well separated</li>
<li>Sum of Squared Errors, Silhouette score, R<sup>2</sup> index, &#x2026;</li>

</ul>

</section>
</section>
<section>
<section id="slide-orgc5b5dba">
<h3 id="orgc5b5dba">Limitations</h3>
<div class="outline-text-3" id="text-orgc5b5dba">
</div>
</section>
<section id="slide-org84a6588">
<h4 id="org84a6588">General</h4>
<ul>
<li>generally clustering algorithms do not perform well with time series</li>
<li>dimensionality, noise and the dynamic nature of time series are problematic</li>
<li>dimensionality reduction inherently brings <b>information loss</b></li>
<li>implementations usually contain experimental flaws (data and implementation bias)</li>
<li>limits the generalizability of study results to real-world problems</li>

</ul>
</section>
<section id="slide-org79bd332">
<h4 id="org79bd332">Research</h4>
<ul>
<li>research in this field is primarily focused on univariate time series</li>
<li>limited scope of time series are used for time series clustering research</li>

</ul>
</section>
<section id="slide-org7034f9b">
<h4 id="org7034f9b">Simlarity metrics</h4>
<ul>
<li>no framework for choosing appropriate distance metric exists</li>
<li>the user needs to choose between generally sensitive metrics (e.g. ED) and computationally expensive metrics (e.g. DTW)</li>
<li>additionally very few metrics exceed the ED performance</li>

</ul>
</section>
<section id="slide-org3365688">
<h4 id="org3365688">Algorithms I</h4>
<ul>
<li>non-globular shapes - partional methods</li>
<li>property that is visually not observable in high-dimensional data and are negatively impacted by outliers and noise</li>

</ul>
</section>
<section id="slide-org47fc229">
<h4 id="org47fc229">Algorithms II</h4>
<ul>
<li>having to define parameters of algorithms in part is counter to the idea of learning patterns from the data without input</li>
<li>other algorithm categories address these issues at the price of computational complexity and infeasibility for large data sets</li>

</ul>
</section>
</section>
<section>
<section id="slide-org5544656">
<h3 id="org5544656">Conclusions and things you should remember</h3>
<div class="outline-text-3" id="text-org5544656">
</div>
</section>
<section id="slide-org33e47a6">
<h4 id="org33e47a6">Missing framework for times series clustering</h4>
<ul>
<li>no clear pattern emerged for methods or metrics are to be used in which circumstances</li>
<li>likely due to lack of generalizability of the found results</li>

</ul>
</section>
<section id="slide-orge6cd41e">
<h4 id="orge6cd41e">Researching towards more complexity</h4>
<ul>
<li>research is aiming to add more complexity</li>
<li>e.g. hybrid methods</li>
<li>may not serve the goals of finding meaningful algorithms</li>

</ul>
</section>
<section id="slide-org54f3b30">
<h4 id="org54f3b30">Our proposal</h4>
<ul>
<li>focus research efforts more on finding fundamental truths about this process</li>
<li>when to use/avoid certain metrics or algorithms</li>
<li>clarity here: may improve general understanding</li>

</ul>
</section>
</section>
<section>
<section id="slide-orgeebbe43">
<h3 id="orgeebbe43">Thank you. Which questions do you have?</h3>
<p>
<a href="https://philippbeer.github.io/unic/501_final_pres/501_ts_c_rev.pdf">(Details and the analyzed papers can be found in the literature review)</a>
</p>
</section>
</section>
</div>
</div>
<script src="https://cdn.jsdelivr.net/npm/reveal.js/dist/reveal.js"></script>

<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({
multiplex: {
    secret: '', // null if client
    id: '', // id, obtained from socket.io server
    url: '' // Location of socket.io server
},

// Optional libraries used to extend on reveal.js
dependencies: [
{src: './org-reveal-animate.js/'},
 { src: 'https://cdn.jsdelivr.net/npm/reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
 { src: 'https://cdn.jsdelivr.net/npm/reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
 { src: 'https://cdn.jsdelivr.net/npm/reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
 { src: 'https://cdn.jsdelivr.net/npm/reveal.js/plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
 { src: 'https://cdn.jsdelivr.net/npm/reveal.js/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }]
});


</script>
</body>
</html>
